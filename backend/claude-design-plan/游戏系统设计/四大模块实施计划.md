# AI驱动RPG游戏后端 - 四大模块实施计划（修订版）

> 本计划基于深度代码探索、架构评审反馈和用户决策修订，确保与现有代码完全对齐。

---

## 概述与优先级

| 模块 | 目标 | 优先级 | 依赖 |
|------|------|--------|------|
| 2. 地点子节点 | key_features升级为可导航子节点 | **P0 (基础)** | 无 |
| 3. 三层NPC AI | 快速系统→潜意识→深度思考 + 预热机制 | **P1** | 无 |
| 1. 主线章节系统 | 主线→章节→地图→地点 四层结构 | **P1** | Module 2 |
| 4. 路人NPC聚合 | PASSERBY按地点聚合，共享记忆图谱 | **P2** | Module 2, 3 |

---

## 用户决策确认

| 决策项 | 用户选择 | 实现方式 |
|--------|----------|----------|
| 子地点时间消耗 | 后期硬编码，暂不消耗 | `SubLocation.travel_time_minutes = 0` |
| 章节进度存储 | GameSessionState.metadata | `metadata.narrative` 字段 |
| 路人共享记忆 | 图谱化，按地图/子地点层级 | GraphStore 新增 `graph_type="location"` |
| Fast层recall_memory | 允许禁用 | 使用预热缓存替代实时检索 |
| 潜意识服务Fast层 | 透明预热机制 | SubconsciousPrewarmer + ReadyContextCache |

---

## 实施顺序

```
Phase 1 (基础层) ─────────────────────────────
│
├─ Module 2: 地点子节点
│  • area_navigator.py 内定义 SubLocation
│  • 保留 resolve_location_name() 签名
│  • 新增 resolve_location() 返回 tuple
│
└─ Module 3: 三层NPC AI (可并行)
   • 潜意识预热机制
   • Fast层使用缓存上下文
   • 层级路由控制

Phase 2 (功能层) ─────────────────────────────
│
├─ Module 1: 主线章节系统
│  • 进度存储在 session.metadata.narrative
│  • 事件触发挂钩现有记录方法
│
└─ Module 4: 路人聚合存储
   • 路径: maps/{map_id}/passerby_pool
   • 共享记忆图谱化到地图/子地点

Phase 3 (集成测试) ───────────────────────────
```

---

## Module 2: 地点子节点系统

### 2.1 目标
将 `key_features`（字符串列表）升级为可导航的子地点，**不破坏现有接口**。

### 2.2 关键修改

**文件: `app/services/area_navigator.py`**

```python
# 在文件内定义（不依赖 worldbook_graphizer/models.py）
@dataclass
class SubLocation:
    """地图内的子地点"""
    id: str
    name: str
    description: str = ""
    parent_map_id: str = ""
    atmosphere: Optional[str] = None
    interaction_type: str = "visit"  # visit/shop/quest/rest
    available_actions: List[str] = field(default_factory=list)
    resident_npcs: List[str] = field(default_factory=list)
    passerby_spawn_rate: float = 0.3
    travel_time_minutes: int = 0  # 同地图内暂不消耗时间

@dataclass
class MapArea:
    # ... 现有字段保持不变 ...
    sub_locations: Dict[str, SubLocation] = field(default_factory=dict)  # 新增

class AreaNavigator:
    def _load_maps(self, maps_data: List[Dict]) -> Dict[str, MapArea]:
        """修改：解析 sub_locations 字段"""
        for map_dict in maps_data:
            # ... 现有解析逻辑 ...

            # 新增：解析子地点
            sub_locs = {}
            for sl_dict in map_dict.get("sub_locations", []):
                sub_loc = SubLocation(
                    id=sl_dict["id"],
                    name=sl_dict["name"],
                    description=sl_dict.get("description", ""),
                    parent_map_id=map_dict["id"],
                    # ... 其他字段 ...
                )
                sub_locs[sl_dict["id"]] = sub_loc

            # 向后兼容：从 key_features 生成默认子地点
            if not sub_locs and map_dict.get("key_features"):
                for i, feature in enumerate(map_dict["key_features"]):
                    sl_id = f"feature_{i}"
                    sub_locs[sl_id] = SubLocation(
                        id=sl_id,
                        name=feature,
                        parent_map_id=map_dict["id"]
                    )

            area.sub_locations = sub_locs

    # 保留原签名（向后兼容）
    def resolve_location_name(self, name: str) -> Optional[str]:
        """原有方法保持不变，只返回 map_id"""
        # ... 现有逻辑不变 ...

    # 新增方法
    def resolve_location(self, name: str) -> Tuple[Optional[str], Optional[str]]:
        """
        解析位置名称，返回 (map_id, sub_location_id)

        Returns:
            (map_id, None) - 匹配到地图
            (map_id, sub_loc_id) - 匹配到子地点
            (None, None) - 未匹配
        """
        # 1. 先尝试匹配地图名
        map_id = self.resolve_location_name(name)
        if map_id:
            return (map_id, None)

        # 2. 在所有地图的子地点中搜索
        name_lower = name.lower()
        for mid, area in self._maps.items():
            for sl_id, sl in area.sub_locations.items():
                if name_lower in sl.name.lower() or name_lower == sl_id.lower():
                    return (mid, sl_id)

        return (None, None)

    def get_sub_locations(self, map_id: str) -> List[SubLocation]:
        """获取地图内所有子地点"""
        area = self._maps.get(map_id)
        if not area:
            return []
        return list(area.sub_locations.values())

    def get_sub_location(self, map_id: str, sub_loc_id: str) -> Optional[SubLocation]:
        """获取特定子地点"""
        area = self._maps.get(map_id)
        if not area:
            return None
        return area.sub_locations.get(sub_loc_id)
```

**文件: `app/services/game_master_service.py`**

> **关键修正**：使用 `_get_navigator(world_id)` 获取导航器，`self.get_context()` 获取上下文（内存缓存），不需要 `_save_context()`

```python
@dataclass
class GameContext:
    # ... 现有字段 ...
    current_sub_location: Optional[str] = None  # 新增

class GameMasterService:
    async def get_current_location(self, world_id: str, session_id: str) -> Dict:
        """修改：返回包含子地点信息，保留原有字段"""
        context = self.get_context(world_id, session_id)  # 使用现有方法
        navigator = self._get_navigator(world_id)  # 使用现有方法
        location = navigator.get_area(context.current_location)

        # 保留原有返回字段
        result = {
            "map_id": context.current_location,
            "map_name": location.name if location else None,
            "description": location.description if location else None,
            "available_destinations": [],  # 保留原有字段
            "npcs_present": [],  # 保留原有字段
            # 新增子地点信息
            "sub_location_id": context.current_sub_location,
            "sub_location_name": None,
            "available_sub_locations": [],
        }

        if location:
            # 保留原有字段填充
            result["available_destinations"] = navigator.get_available_destinations(
                context.current_location
            )
            result["npcs_present"] = location.resident_npcs

            # 新增子地点信息
            result["available_sub_locations"] = [
                {"id": sl.id, "name": sl.name, "type": sl.interaction_type}
                for sl in location.sub_locations.values()
            ]
            if context.current_sub_location:
                sl = location.sub_locations.get(context.current_sub_location)
                if sl:
                    result["sub_location_name"] = sl.name
                    result["npcs_present"] = sl.resident_npcs  # 更新为子地点NPC

        return result

    async def enter_sub_location(
        self,
        world_id: str,
        session_id: str,
        sub_location_id: str
    ) -> Dict[str, Any]:
        """进入当前地图的子地点（只改内存context）"""
        context = self.get_context(world_id, session_id)
        navigator = self._get_navigator(world_id)

        # 验证子地点存在
        sub_loc = navigator.get_sub_location(
            context.current_location,
            sub_location_id
        )
        if not sub_loc:
            return {"success": False, "error": "子地点不存在"}

        # 更新内存中的上下文（不需要持久化，重启后从session恢复）
        context.current_sub_location = sub_location_id

        # 生成进入描述
        description = await self._generate_sub_location_description(sub_loc)

        return {
            "success": True,
            "sub_location": {
                "id": sub_loc.id,
                "name": sub_loc.name,
                "description": description,
                "available_actions": sub_loc.available_actions,
                "npcs_present": sub_loc.resident_npcs,
            }
        }

    async def _parse_player_intent(self, context: GameContext, player_input: str) -> Dict:
        """修改：意图识别包含子地点"""
        navigator = self._get_navigator(context.world_id)  # 使用现有方法
        current_area = navigator.get_area(context.current_location)

        # 构建提示时包含可用子地点
        sub_locations_str = ""
        if current_area and current_area.sub_locations:
            sub_locs = [f"- {sl.name} ({sl.id})" for sl in current_area.sub_locations.values()]
            sub_locations_str = f"\n当前地点内的子地点：\n" + "\n".join(sub_locs)

        prompt = f"""
        当前位置: {context.current_location}
        当前子地点: {context.current_sub_location or "无"}
        {sub_locations_str}

        玩家输入: {player_input}

        判断玩家意图...
        """
        # ... 调用LLM解析 ...
```

**文件: `data/goblin_slayer/structured/maps.json`**

```json
{
  "maps": [
    {
      "id": "frontier_town",
      "name": "边境小镇",
      "description": "...",
      "key_features": ["冒险者公会分部", "铁匠铺", "酒馆"],
      "sub_locations": [
        {
          "id": "guild_hall",
          "name": "冒险者公会分部",
          "description": "当地的冒险者公会分部，墙上贴满了任务委托",
          "interaction_type": "quest",
          "resident_npcs": ["guild_girl"],
          "available_actions": ["接任务", "情报收集", "交任务", "查看排行榜"]
        },
        {
          "id": "blacksmith",
          "name": "铁匠铺",
          "description": "铁锤敲击的声音不绝于耳，热浪扑面而来",
          "interaction_type": "shop",
          "resident_npcs": ["blacksmith_owner"],
          "available_actions": ["武器修理", "装备购买", "定制装备"]
        },
        {
          "id": "tavern",
          "name": "酒馆",
          "description": "冒险者们聚集的地方，充满了欢笑和故事",
          "interaction_type": "visit",
          "resident_npcs": ["tavern_keeper"],
          "passerby_spawn_rate": 0.5,
          "available_actions": ["休息", "打听消息", "招募同伴", "用餐"]
        }
      ],
      "connections": [...]
    }
  ]
}
```

### 2.3 修改文件清单

| 文件 | 修改类型 | 内容 |
|------|----------|------|
| `app/services/area_navigator.py` | 修改 | 添加SubLocation定义，_load_maps解析，新增方法 |
| `app/services/game_master_service.py` | 修改 | GameContext新增字段，enter_sub_location方法 |
| `app/routers/game_master.py` | 修改 | 添加子地点相关API端点 |
| `data/goblin_slayer/structured/maps.json` | 修改 | 添加sub_locations数据 |

---

## Module 3: 三层NPC AI系统（含预热机制）

### 3.1 目标
实现分层AI响应，潜意识层透明服务Fast层：
- **Fast层**: 无thinking，禁用recall_memory，使用预热缓存
- **Subconscious层**: Flash+thinking，保留recall_memory
- **Deep层**: Pro+高thinking，复杂推理

### 3.2 架构设计

```
┌─────────────────────────────────────────────────────────────┐
│                 场景/位置变化触发                             │
└─────────────────────┬───────────────────────────────────────┘
                      │
                      ▼
┌─────────────────────────────────────────────────────────────┐
│  SubconsciousPrewarmer (潜意识预热器)                        │
│  ──────────────────────────────────────────────────────────│
│  • 场景进入时：同步预热，检索相关记忆                          │
│  • 对话进行中：异步更新，主题检测后补充上下文                    │
│  • 模型: gemini-3-flash + thinking                          │
└─────────────────────┬───────────────────────────────────────┘
                      │ 写入
                      ▼
┌─────────────────────────────────────────────────────────────┐
│  ReadyContextCache (就绪上下文缓存)                          │
│  ──────────────────────────────────────────────────────────│
│  {                                                          │
│    "scene_context": "当前在边境酒馆...",                     │
│    "relevant_people": ["女神官在场"],                        │
│    "recent_events": ["昨天的哥布林袭击"],                     │
│    "npc_mood": "友好",                                      │
│    "topics_primed": ["哥布林", "任务"],                      │
│    "last_updated": timestamp                                │
│  }                                                          │
│  TTL: 5分钟                                                 │
└─────────────────────┬───────────────────────────────────────┘
                      │ 读取（同步）
                      ▼
┌─────────────────────────────────────────────────────────────┐
│  TieredAIService (分层AI服务)                                │
│  ──────────────────────────────────────────────────────────│
│  Fast层:                                                    │
│  • 模型: gemini-2.5-flash-lite (无thinking)                 │
│  • 禁用工具调用                                              │
│  • 使用缓存上下文                                            │
│  • 目标延迟: <100ms                                         │
│                                                             │
│  Subconscious层:                                            │
│  • 模型: gemini-3-flash + thinking                          │
│  • 启用 recall_memory 工具                                  │
│  • 目标延迟: <2s                                            │
│                                                             │
│  Deep层:                                                    │
│  • 模型: gemini-3-pro + high thinking                       │
│  • 启用所有工具                                              │
│  • 目标延迟: <10s                                           │
└─────────────────────────────────────────────────────────────┘
```

### 3.3 新建文件

**文件: `app/services/context_cache.py` (新建)**

```python
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, Optional, Any
import asyncio

@dataclass
class CacheEntry:
    """缓存条目"""
    context: Dict[str, Any]
    created_at: datetime
    last_accessed: datetime

    def is_expired(self, ttl_seconds: int) -> bool:
        return (datetime.now() - self.created_at).total_seconds() > ttl_seconds

class ReadyContextCache:
    """为Fast层准备的就绪上下文缓存"""

    def __init__(self, ttl_seconds: int = 300):  # 5分钟TTL
        self._cache: Dict[str, CacheEntry] = {}
        self._ttl = ttl_seconds
        self._lock = asyncio.Lock()

    def _make_key(self, npc_id: str, location_id: str) -> str:
        return f"{npc_id}:{location_id}"

    async def get_context(
        self,
        npc_id: str,
        location_id: str
    ) -> Optional[Dict[str, Any]]:
        """获取缓存的上下文（Fast层同步调用）"""
        key = self._make_key(npc_id, location_id)
        entry = self._cache.get(key)

        if entry is None:
            return None

        if entry.is_expired(self._ttl):
            del self._cache[key]
            return None

        entry.last_accessed = datetime.now()
        return entry.context

    async def set_context(
        self,
        npc_id: str,
        location_id: str,
        context: Dict[str, Any]
    ):
        """设置缓存上下文（潜意识层调用）"""
        async with self._lock:
            key = self._make_key(npc_id, location_id)
            self._cache[key] = CacheEntry(
                context=context,
                created_at=datetime.now(),
                last_accessed=datetime.now()
            )

    async def update_context(
        self,
        npc_id: str,
        location_id: str,
        updates: Dict[str, Any]
    ):
        """增量更新缓存（潜意识后台更新）"""
        async with self._lock:
            key = self._make_key(npc_id, location_id)
            entry = self._cache.get(key)
            if entry and not entry.is_expired(self._ttl):
                entry.context.update(updates)
                entry.last_accessed = datetime.now()

    async def invalidate(self, npc_id: str, location_id: Optional[str] = None):
        """失效缓存（场景切换时）"""
        async with self._lock:
            if location_id:
                key = self._make_key(npc_id, location_id)
                self._cache.pop(key, None)
            else:
                # 失效该NPC的所有缓存
                keys_to_remove = [k for k in self._cache if k.startswith(f"{npc_id}:")]
                for k in keys_to_remove:
                    del self._cache[k]
```

**文件: `app/services/subconscious_prewarmer.py` (新建)**

> **关键修正**：`pro_requests_memory()` 返回 `MemoryInjection` 对象，需用 `.text`、`.source_nodes` 访问

```python
from typing import Dict, Any, Optional, Set
import asyncio
from datetime import datetime

from app.services.context_cache import ReadyContextCache
from app.services.flash_service import FlashService
from app.services.flash_pro_bridge import FlashProBridge
from app.models.npc_instance import MemoryInjection  # 返回类型

class SubconsciousPrewarmer:
    """潜意识预热服务 - 透明服务Fast层"""

    def __init__(
        self,
        flash_service: FlashService,
        flash_pro_bridge: FlashProBridge,
        cache: ReadyContextCache,
    ):
        self._flash = flash_service
        self._bridge = flash_pro_bridge
        self._cache = cache
        self._background_tasks: Set[asyncio.Task] = set()

    async def prewarm_for_scene(
        self,
        world_id: str,
        npc_id: str,
        location_id: str,
        sub_location_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        场景进入时预热（同步，阻塞直到完成）

        Returns:
            预热后的上下文字典
        """
        # 1. 检索场景相关记忆
        scene_query = f"当前场景：{location_id}"
        if sub_location_id:
            scene_query += f"，子地点：{sub_location_id}"

        # 返回 MemoryInjection 对象
        memory_injection: MemoryInjection = await self._bridge.pro_requests_memory(
            query=scene_query,
            world_id=world_id,
            npc_id=npc_id,
            use_subgraph=True,
        )

        # 2. 构建就绪上下文（使用正确的对象属性）
        context = {
            "scene_context": memory_injection.text if memory_injection else "",
            "source_nodes": memory_injection.source_nodes if memory_injection else [],
            "confidence": memory_injection.confidence if memory_injection else 0.0,
            "query_intent": memory_injection.query_intent if memory_injection else "",
            "npc_mood": "neutral",
            "topics_primed": [],
            "last_updated": datetime.now().isoformat(),
        }

        # 从 full_context 提取更多信息
        if memory_injection and memory_injection.full_context:
            for ctx in memory_injection.full_context:
                if ctx.get("type") == "event_group":
                    context["topics_primed"].extend(
                        ctx.get("participants", [])
                    )

        # 3. 写入缓存
        await self._cache.set_context(npc_id, location_id, context)

        return context

    def schedule_background_update(
        self,
        world_id: str,
        npc_id: str,
        location_id: str,
        dialogue_content: str,
    ):
        """对话后异步更新（非阻塞）"""
        task = asyncio.create_task(
            self._background_update(world_id, npc_id, location_id, dialogue_content)
        )
        self._background_tasks.add(task)
        task.add_done_callback(self._background_tasks.discard)

    async def _background_update(
        self,
        world_id: str,
        npc_id: str,
        location_id: str,
        dialogue_content: str,
    ):
        """后台更新上下文"""
        try:
            # 1. 检测对话中的新主题
            topics = await self._detect_topics(dialogue_content)

            if not topics:
                return  # 无新主题，不更新

            # 2. 检索相关记忆
            for topic in topics[:3]:  # 最多处理3个新主题
                memory_injection: MemoryInjection = await self._bridge.pro_requests_memory(
                    query=f"关于{topic}的记忆",
                    world_id=world_id,
                    npc_id=npc_id,
                )

                if memory_injection and memory_injection.text:
                    # 3. 增量更新缓存
                    await self._cache.update_context(
                        npc_id,
                        location_id,
                        {
                            "topics_primed": topics,
                            f"memory_{topic}": memory_injection.text,
                            "last_updated": datetime.now().isoformat(),
                        }
                    )
        except Exception as e:
            # 后台任务失败不影响主流程
            pass

    async def _detect_topics(self, text: str) -> list:
        """检测文本中的主题（简单实现，可扩展为LLM检测）"""
        # TODO: 可以用LLM做更智能的主题检测
        keywords = ["哥布林", "任务", "装备", "同伴", "危险", "传闻"]
        return [kw for kw in keywords if kw in text]
```

**文件: `app/services/tiered_ai_service.py` (新建)**

```python
from enum import Enum
from typing import Dict, Any, Optional
from dataclasses import dataclass

from app.config import settings
from app.services.context_cache import ReadyContextCache
from app.services.subconscious_prewarmer import SubconsciousPrewarmer
from app.tools.worldbook_graphizer.models import NPCTier

class AITier(str, Enum):
    FAST = "fast"              # 无thinking，禁用工具
    SUBCONSCIOUS = "subconscious"  # Flash + thinking，启用recall_memory
    DEEP = "deep"              # Pro + 高thinking，全工具

@dataclass
class TieredResponse:
    """分层响应结果"""
    content: str
    tier_used: AITier
    latency_ms: float
    recalled_memory: Optional[str] = None
    cache_hit: bool = False

# 路由矩阵
TIER_ROUTING = {
    # (npc_tier, complexity) -> ai_tier
    (NPCTier.MAIN, "high"): AITier.DEEP,
    (NPCTier.MAIN, "medium"): AITier.SUBCONSCIOUS,
    (NPCTier.MAIN, "low"): AITier.SUBCONSCIOUS,  # MAIN至少用潜意识

    (NPCTier.SECONDARY, "high"): AITier.SUBCONSCIOUS,
    (NPCTier.SECONDARY, "medium"): AITier.SUBCONSCIOUS,
    (NPCTier.SECONDARY, "low"): AITier.FAST,

    (NPCTier.PASSERBY, "high"): AITier.FAST,  # PASSERBY全用Fast
    (NPCTier.PASSERBY, "medium"): AITier.FAST,
    (NPCTier.PASSERBY, "low"): AITier.FAST,
}

class ComplexityAnalyzer:
    """查询复杂度分析器"""

    def analyze(self, query: str, context: Dict) -> str:
        """
        返回 "low" / "medium" / "high"

        考虑因素:
        - 查询长度
        - 是否涉及特定人物/事件
        - 是否需要回忆
        - 情感复杂度
        """
        # 简单实现，可扩展
        query_lower = query.lower()

        # 高复杂度指标
        high_indicators = ["为什么", "怎么想", "记得", "上次", "关于...的看法"]
        if any(ind in query_lower for ind in high_indicators):
            return "high"

        # 低复杂度指标
        low_indicators = ["你好", "再见", "谢谢", "多少钱", "在哪"]
        if any(ind in query_lower for ind in low_indicators):
            return "low"

        return "medium"

class TieredAIService:
    """三层AI响应服务"""

    def __init__(
        self,
        context_cache: ReadyContextCache,
        prewarmer: SubconsciousPrewarmer,
        pro_service,  # 现有的ProService（不是ProLLMService）
        llm_service,  # LLMService基类，用于generate_simple
    ):
        self._cache = context_cache
        self._prewarmer = prewarmer
        self._pro_service = pro_service  # 用于Subconscious/Deep层
        self._llm_service = llm_service  # 用于Fast层的generate_simple
        self._complexity = ComplexityAnalyzer()

    def determine_tier(
        self,
        npc_tier: NPCTier,
        query: str,
        context: Dict,
        force_tier: Optional[AITier] = None,
    ) -> AITier:
        """确定应使用的AI层级"""
        if force_tier:
            return force_tier

        complexity = self._complexity.analyze(query, context)
        return TIER_ROUTING.get((npc_tier, complexity), AITier.SUBCONSCIOUS)

    async def respond(
        self,
        world_id: str,
        npc_id: str,
        npc_tier: NPCTier,
        query: str,
        location_id: str,
        npc_profile: Dict,
        force_tier: Optional[AITier] = None,
    ) -> TieredResponse:
        """分层响应"""
        import time
        start = time.time()

        tier = self.determine_tier(npc_tier, query, {}, force_tier)

        if tier == AITier.FAST:
            response = await self._respond_fast(
                world_id, npc_id, query, location_id, npc_profile
            )
        elif tier == AITier.SUBCONSCIOUS:
            response = await self._respond_subconscious(
                world_id, npc_id, query, location_id, npc_profile
            )
        else:  # DEEP
            response = await self._respond_deep(
                world_id, npc_id, query, location_id, npc_profile
            )

        latency = (time.time() - start) * 1000

        return TieredResponse(
            content=response["content"],
            tier_used=tier,
            latency_ms=latency,
            recalled_memory=response.get("recalled_memory"),
            cache_hit=response.get("cache_hit", False),
        )

    async def _respond_fast(
        self,
        world_id: str,
        npc_id: str,
        query: str,
        location_id: str,
        npc_profile: Dict,
    ) -> Dict:
        """Fast层响应 - 使用预热缓存，禁用工具"""
        # 1. 获取缓存上下文
        cached_context = await self._cache.get_context(npc_id, location_id)
        cache_hit = cached_context is not None

        if not cached_context:
            # 缓存未命中，使用最小上下文
            cached_context = {"scene_context": "", "topics_primed": []}

        # 2. 构建prompt（包含缓存上下文）
        prompt = self._build_fast_prompt(query, npc_profile, cached_context)

        # 3. 调用fast模型（无thinking，无工具）
        # 使用 LLMService.generate_simple()（现有方法）
        response = await self._llm_service.generate_simple(prompt)

        # 4. 异步通知潜意识更新
        self._prewarmer.schedule_background_update(
            world_id, npc_id, location_id, query
        )

        return {
            "content": response,
            "cache_hit": cache_hit,
        }

    async def _respond_subconscious(
        self,
        world_id: str,
        npc_id: str,
        query: str,
        location_id: str,
        npc_profile: Dict,
    ) -> Dict:
        """Subconscious层响应 - 保留recall_memory工具"""
        # 使用现有ProLLMService的完整chat流程
        result = await self._pro_llm.chat(
            world_id=world_id,
            npc_id=npc_id,
            query=query,
            profile=npc_profile,
            model_override=settings.gemini_subconscious_model,
            thinking_config={"enabled": True, "level": "medium"},
            enable_tools=True,  # 启用recall_memory
        )

        return {
            "content": result.response,
            "recalled_memory": result.recalled_memory,
        }

    async def _respond_deep(
        self,
        world_id: str,
        npc_id: str,
        query: str,
        location_id: str,
        npc_profile: Dict,
    ) -> Dict:
        """Deep层响应 - Pro模型 + 高thinking"""
        result = await self._pro_llm.chat(
            world_id=world_id,
            npc_id=npc_id,
            query=query,
            profile=npc_profile,
            model_override=settings.gemini_deep_model,
            thinking_config={"enabled": True, "level": "high"},
            enable_tools=True,
        )

        return {
            "content": result.response,
            "recalled_memory": result.recalled_memory,
        }

    def _build_fast_prompt(
        self,
        query: str,
        npc_profile: Dict,
        cached_context: Dict,
    ) -> str:
        """构建Fast层prompt"""
        return f"""你是{npc_profile.get('name', 'NPC')}。
性格: {npc_profile.get('personality', '')}
说话方式: {npc_profile.get('speech_pattern', '')}

当前场景: {cached_context.get('scene_context', '未知')}
相关话题: {', '.join(cached_context.get('topics_primed', []))}

玩家说: {query}

请简短回应（1-2句话）:"""
```

### 3.4 配置修改

**文件: `app/config.py`**

```python
class Settings(BaseModel):
    # ... 现有配置 ...

    # 三层AI模型配置
    gemini_fast_model: str = os.getenv(
        "GEMINI_FAST_MODEL",
        "gemini-2.5-flash-lite"  # 或回退到 gemini_flash_model
    )
    gemini_subconscious_model: str = os.getenv(
        "GEMINI_SUBCONSCIOUS_MODEL",
        "gemini-3-flash-preview"
    )
    gemini_deep_model: str = os.getenv(
        "GEMINI_DEEP_MODEL",
        "gemini-3-pro-preview"
    )

    # 缓存配置
    context_cache_ttl_seconds: int = 300  # 5分钟
```

### 3.5 集成修改

> **关键修正**：
> 1. ProLLMService 现有方法是 `chat()` 和 `chat_simple()`
> 2. `LLMService` (基类) 有 `generate_simple()` 方法
> 3. `_handle_dialogue()` 必须保留 ContextWindow/graphize 流程，只替换生成回复处

**文件: `app/services/pro_llm_service.py`**

```python
class ProLLMService:
    async def chat(
        self,
        world_id: str,
        character_id: str,
        user_message: str,
        profile: Dict,
        state: Dict,
        scene: Dict,
        conversation_history: List[Dict],
        injected_memory: Optional[str] = None,
        # 新增参数
        model_override: Optional[str] = None,
        thinking_config: Optional[Dict] = None,
        enable_tools: bool = True,
    ) -> Dict[str, Any]:
        """修改：支持模型和thinking配置覆盖"""
        # 选择模型
        model = model_override or settings.gemini_main_model

        # 配置thinking
        if thinking_config:
            thinking_enabled = thinking_config.get("enabled", True)
            thinking_level = thinking_config.get("level", "medium")
        else:
            thinking_enabled = settings.thinking_enabled
            thinking_level = settings.thinking_level

        # 配置工具
        tools = []
        if enable_tools:
            tools = [self._recall_memory_tool]

        # ... 其余逻辑保持不变 ...

    # 现有方法，保持不变
    async def chat_simple(
        self,
        world_id: str,
        character_id: str,
        user_message: str,
        profile: Dict,
        conversation_history: List[Dict],
    ) -> str:
        """简化版chat，只返回文本"""
        # ... 现有实现 ...
```

**文件: `app/services/llm_service.py`** (基类已有)

```python
class LLMService:
    # 现有方法，被 flash_pro_bridge 使用
    async def generate_simple(self, prompt: str) -> str:
        """简单生成，无工具，用于Fast层"""
        # ... 现有实现 ...
```

**文件: `app/services/game_master_service.py`**

> **关键**：保留 ContextWindow/graphize 流程，只替换生成回复部分

```python
class GameMasterService:
    def __init__(self, ...):
        # ... 现有初始化 ...

        # 新增：三层AI组件
        self._context_cache = ReadyContextCache(settings.context_cache_ttl_seconds)
        self._prewarmer = SubconsciousPrewarmer(
            self.flash_service,
            self.flash_pro_bridge,
            self._context_cache,
        )
        self._tiered_ai = TieredAIService(
            self._context_cache,
            self._prewarmer,
            self.pro_service,  # 使用现有 pro_service
            self.llm_service,  # 传入基类用于 generate_simple
        )

    async def enter_scene(self, world_id, session_id, scene_info):
        """修改：场景进入时触发预热"""
        # ... 现有逻辑 ...

        # 预热当前场景中的NPC上下文（可选，根据性能需求）
        context = self.get_context(world_id, session_id)
        for npc_id in scene_info.get("npcs", []):
            await self._prewarmer.prewarm_for_scene(
                world_id=world_id,
                npc_id=npc_id,
                location_id=context.current_location,
                sub_location_id=context.current_sub_location,
            )

    async def _handle_dialogue(self, context, npc_id, player_message):
        """
        修改：使用分层AI，但保留完整的 ContextWindow/graphize 流程

        关键：只替换"生成回复"的那一行，不改变上下文管理逻辑
        """
        # ========== 保留：获取NPC实例 ==========
        npc_instance = await self.instance_manager.get_or_create(
            world_id=context.world_id,
            npc_id=npc_id,
            config=...,
        )
        npc_profile = await self._get_npc_profile(context.world_id, npc_id)

        # ========== 保留：添加消息到ContextWindow ==========
        add_result = npc_instance.context_window.add_message(
            role="user",
            content=player_message,
        )

        # ========== 保留：检查graphize触发 ==========
        if add_result.should_graphize:
            graphize_result = await self._trigger_graphize(
                npc_instance, npc_profile, context
            )

        # ========== 保留：构建场景上下文 ==========
        scene_context = self._build_scene_context(context)
        conversation_history = npc_instance.context_window.get_recent_messages(20)

        # ========== 修改：使用TieredAI生成回复 ==========
        npc_tier = npc_instance.config.tier if npc_instance.config else NPCTier.SECONDARY

        # 根据tier决定生成方式
        tier = self._tiered_ai.determine_tier(npc_tier, player_message, {})

        if tier == AITier.FAST:
            # Fast层：使用缓存上下文，跳过recall_memory
            response = await self._tiered_ai.respond(
                world_id=context.world_id,
                npc_id=npc_id,
                npc_tier=npc_tier,
                query=player_message,
                location_id=context.current_location,
                npc_profile=npc_profile,
                force_tier=AITier.FAST,
            )
            npc_response = response.content
            recalled_memory = None
        else:
            # Subconscious/Deep层：使用现有pro_service.chat()保留完整功能
            result = await self.pro_service.chat(
                world_id=context.world_id,
                character_id=npc_id,
                user_message=player_message,
                profile=npc_profile,
                state=npc_instance.state.dict() if npc_instance.state else {},
                scene=scene_context,
                conversation_history=conversation_history,
                # 新增参数
                model_override=settings.gemini_deep_model if tier == AITier.DEEP else None,
                thinking_config={"enabled": True, "level": "high" if tier == AITier.DEEP else "medium"},
                enable_tools=True,
            )
            npc_response = result["response"]
            recalled_memory = result.get("recalled_memory")

        # ========== 保留：添加NPC回复到ContextWindow ==========
        npc_instance.context_window.add_message(
            role="assistant",
            content=npc_response,
        )
        npc_instance.state.conversation_turn_count += 1

        # ========== 保留：记录对话事件 ==========
        await self._record_dialogue_event(context, npc_id, player_message, npc_response)

        # ========== 返回结果（新增tier信息） ==========
        return {
            "response": npc_response,
            "speaker": npc_profile.get("name", npc_id),
            "tier_used": tier.value,
            "recalled_memory": recalled_memory,
            "instance_info": {
                "context_tokens": npc_instance.context_window.current_tokens,
                "turn_count": npc_instance.state.conversation_turn_count,
            },
        }
```

### 3.6 修改文件清单

| 文件 | 修改类型 | 内容 |
|------|----------|------|
| `app/services/context_cache.py` | **新建** | ReadyContextCache |
| `app/services/subconscious_prewarmer.py` | **新建** | SubconsciousPrewarmer |
| `app/services/tiered_ai_service.py` | **新建** | AITier, TieredAIService |
| `app/config.py` | 修改 | 添加三层模型配置 |
| `app/services/pro_llm_service.py` | 修改 | 支持model_override, thinking_config, enable_tools |
| `app/services/game_master_service.py` | 修改 | 集成TieredAIService，场景预热 |

---

## Module 1: 主线章节系统

### 1.1 目标
创建层级叙事结构，进度持久化到 session.metadata.narrative。

### 1.2 数据模型

**文件: `app/models/narrative.py` (新建)**

```python
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime

class ChapterObjective(BaseModel):
    """章节目标"""
    id: str
    description: str
    completed: bool = False
    completed_at: Optional[datetime] = None

class Chapter(BaseModel):
    """剧情章节"""
    id: str
    mainline_id: str
    name: str
    description: str
    objectives: List[ChapterObjective]
    available_maps: List[str]  # 解锁的地图ID
    trigger_conditions: Dict[str, Any] = {}  # 解锁条件
    completion_conditions: Dict[str, Any] = {}  # 完成条件

class Mainline(BaseModel):
    """主线剧情"""
    id: str
    name: str
    description: str
    chapters: List[str]  # 章节ID列表（有序）

class NarrativeProgress(BaseModel):
    """叙事进度（存储在session.metadata.narrative）"""
    current_mainline: str
    current_chapter: str
    objectives_completed: List[str] = []
    events_triggered: List[str] = []
    chapter_started_at: Optional[datetime] = None
    chapters_completed: List[str] = []
```

### 1.3 服务层

**文件: `app/services/narrative_service.py` (新建)**

```python
from typing import Optional, List, Dict, Any
from app.models.narrative import Mainline, Chapter, NarrativeProgress
from app.services.game_session_store import GameSessionStore

class NarrativeService:
    """主线叙事管理服务"""

    def __init__(self, session_store: GameSessionStore):
        self._session_store = session_store
        self._mainlines: Dict[str, Mainline] = {}
        self._chapters: Dict[str, Chapter] = {}

    async def load_narrative_data(self, world_id: str):
        """加载主线数据（从 mainlines.json）"""
        # 从 data/{world_id}/structured/mainlines.json 加载
        pass

    async def get_progress(
        self,
        world_id: str,
        session_id: str
    ) -> NarrativeProgress:
        """获取当前进度"""
        session = await self._session_store.get_session(world_id, session_id)
        narrative_data = session.metadata.get("narrative", {})

        if not narrative_data:
            # 初始化进度
            return NarrativeProgress(
                current_mainline="goblin_crisis",  # 默认主线
                current_chapter="ch1_awakening",   # 默认章节
            )

        return NarrativeProgress(**narrative_data)

    async def save_progress(
        self,
        world_id: str,
        session_id: str,
        progress: NarrativeProgress,
    ):
        """保存进度到 session.metadata.narrative"""
        # 正确的调用方式：update_session(world_id, session_id, updates: dict)
        await self._session_store.update_session(
            world_id,
            session_id,
            {"metadata": {"narrative": progress.dict()}}  # 合并到metadata
        )

    async def get_available_maps(
        self,
        world_id: str,
        session_id: str,
    ) -> List[str]:
        """获取当前章节可用的地图"""
        progress = await self.get_progress(world_id, session_id)
        chapter = self._chapters.get(progress.current_chapter)

        if not chapter:
            return []

        return chapter.available_maps

    async def trigger_event(
        self,
        world_id: str,
        session_id: str,
        event_id: str,
    ) -> Dict[str, Any]:
        """触发叙事事件，检查章节完成"""
        progress = await self.get_progress(world_id, session_id)

        if event_id not in progress.events_triggered:
            progress.events_triggered.append(event_id)

        # 检查章节完成条件
        chapter = self._chapters.get(progress.current_chapter)
        if chapter and self._check_completion(chapter, progress):
            result = await self._advance_chapter(world_id, session_id, progress)
            return {"chapter_completed": True, "new_chapter": result}

        await self.save_progress(world_id, session_id, progress)
        return {"chapter_completed": False}

    def _check_completion(
        self,
        chapter: Chapter,
        progress: NarrativeProgress,
    ) -> bool:
        """检查章节完成条件"""
        required_events = chapter.completion_conditions.get("events_required", [])
        return all(ev in progress.events_triggered for ev in required_events)

    async def _advance_chapter(
        self,
        world_id: str,
        session_id: str,
        progress: NarrativeProgress,
    ) -> Optional[str]:
        """推进到下一章节"""
        mainline = self._mainlines.get(progress.current_mainline)
        if not mainline:
            return None

        current_idx = mainline.chapters.index(progress.current_chapter)
        if current_idx + 1 >= len(mainline.chapters):
            return None  # 已完成所有章节

        # 记录完成的章节
        progress.chapters_completed.append(progress.current_chapter)

        # 推进到下一章节
        next_chapter = mainline.chapters[current_idx + 1]
        progress.current_chapter = next_chapter
        progress.events_triggered = []  # 重置事件
        progress.chapter_started_at = datetime.now()

        await self.save_progress(world_id, session_id, progress)
        return next_chapter
```

### 1.4 集成修改

**文件: `app/services/game_master_service.py`**

```python
class GameMasterService:
    def __init__(self, ...):
        # ... 现有 ...
        self.narrative_service = NarrativeService(self.session_store)

    async def navigate(self, world_id, session_id, destination):
        """修改：导航前检查地图解锁"""
        # 检查目标地图是否解锁
        available_maps = await self.narrative_service.get_available_maps(
            world_id, session_id
        )

        map_id, sub_loc_id = self.area_navigator.resolve_location(destination)

        if map_id and map_id not in available_maps:
            return {
                "success": False,
                "error": "该地区尚未解锁",
                "hint": "完成当前章节目标后解锁",
                "available_maps": available_maps,
            }

        # ... 继续原有导航逻辑 ...

    async def _record_dialogue_event(self, ...):
        """修改：对话事件后检查叙事触发"""
        # ... 原有记录逻辑 ...

        # 检查是否触发叙事事件
        event_id = self._detect_narrative_event(dialogue_content, npc_id)
        if event_id:
            result = await self.narrative_service.trigger_event(
                world_id, session_id, event_id
            )
            if result.get("chapter_completed"):
                # 可以生成章节完成的叙述
                pass

    def _detect_narrative_event(self, dialogue: str, npc_id: str) -> Optional[str]:
        """检测对话是否触发叙事事件"""
        # 简单实现：特定NPC的首次对话
        # 可扩展为更复杂的条件检测
        event_mapping = {
            "guild_girl": "meet_guild_girl",
            "priestess": "meet_priestess",
        }
        return event_mapping.get(npc_id)
```

### 1.5 数据文件

**文件: `data/goblin_slayer/structured/mainlines.json` (新建)**

```json
{
  "mainlines": [
    {
      "id": "goblin_crisis",
      "name": "哥布林危机篇",
      "description": "初始剧情线，聚焦于哥布林威胁",
      "chapters": ["ch1_awakening", "ch2_first_hunt", "ch3_lair_discovery"]
    }
  ],
  "chapters": [
    {
      "id": "ch1_awakening",
      "mainline_id": "goblin_crisis",
      "name": "觉醒",
      "description": "新手冒险者的第一步",
      "available_maps": ["frontier_town"],
      "objectives": [
        {"id": "obj_meet_guild", "description": "与公会女孩对话"},
        {"id": "obj_first_quest", "description": "接取第一个任务"}
      ],
      "trigger_conditions": {},
      "completion_conditions": {
        "events_required": ["meet_guild_girl", "accept_first_quest"]
      }
    },
    {
      "id": "ch2_first_hunt",
      "mainline_id": "goblin_crisis",
      "name": "初次狩猎",
      "description": "第一次讨伐哥布林",
      "available_maps": ["frontier_town", "goblin_cave_entrance"],
      "objectives": [
        {"id": "obj_prepare", "description": "准备装备"},
        {"id": "obj_hunt", "description": "前往哥布林洞穴"}
      ],
      "trigger_conditions": {
        "chapter_completed": "ch1_awakening"
      },
      "completion_conditions": {
        "events_required": ["enter_goblin_cave", "first_goblin_killed"]
      }
    }
  ]
}
```

### 1.6 修改文件清单

| 文件 | 修改类型 | 内容 |
|------|----------|------|
| `app/models/narrative.py` | **新建** | Mainline, Chapter, NarrativeProgress |
| `app/services/narrative_service.py` | **新建** | NarrativeService |
| `app/services/game_master_service.py` | 修改 | 集成NarrativeService，导航检查 |
| `data/goblin_slayer/structured/mainlines.json` | **新建** | 主线数据 |

---

## Module 4: 路人NPC聚合存储

### 4.1 目标
PASSERBY级别NPC按地点聚合存储，共享地点级记忆图谱。

### 4.2 Firestore结构（与现有一致）

```
worlds/{world_id}/
  maps/{map_id}/
    passerby_pool/
      config          # PasserbySpawnConfig
      sentiment       # float: 地点舆论
      active/         # 当前活跃路人
        {instance_id} # PasserbyInstance
    graphs/
      shared_memory   # 地点级共享记忆图谱

  sub_locations/{sub_loc_id}/
    graphs/
      npc_memory      # 子地点NPC记忆（如铁匠）
```

### 4.3 数据模型

**文件: `app/models/passerby.py` (新建)**

```python
from pydantic import BaseModel
from typing import Dict, List, Optional
from datetime import datetime

class PasserbyInstance(BaseModel):
    """路人NPC运行时实例"""
    instance_id: str
    template_id: str
    map_id: str
    sub_location_id: Optional[str] = None
    name: str
    appearance: str
    personality_snippet: str
    mood: str = "neutral"
    spawn_time: datetime
    interaction_count: int = 0

class PasserbySpawnConfig(BaseModel):
    """路人生成配置"""
    max_concurrent: int = 5
    spawn_interval_minutes: int = 30
    despawn_after_minutes: int = 60
    templates: List[str] = []  # 可用模板ID

class LocationPasserbyPool(BaseModel):
    """地点级路人池"""
    map_id: str
    config: PasserbySpawnConfig
    active_instances: Dict[str, PasserbyInstance] = {}
    sentiment: float = 0.0  # -1到1，地点舆论

class SharedMemoryContribution(BaseModel):
    """共享记忆贡献"""
    contributor_type: str  # "passerby" / "player_action"
    content: str
    timestamp: datetime
    importance: float = 0.5
```

### 4.4 服务层

**文件: `app/services/passerby_service.py` (新建)**

```python
from typing import Dict, Optional, List
from datetime import datetime, timedelta
import random
import uuid

from app.models.passerby import (
    PasserbyInstance, PasserbySpawnConfig,
    LocationPasserbyPool, SharedMemoryContribution
)
from app.services.graph_store import GraphStore
from app.services.tiered_ai_service import TieredAIService, AITier
from app.tools.worldbook_graphizer.models import NPCTier

class PasserbyService:
    """路人NPC管理服务"""

    def __init__(
        self,
        graph_store: GraphStore,
        tiered_ai: TieredAIService,
    ):
        self._graph_store = graph_store
        self._tiered_ai = tiered_ai
        self._pools: Dict[str, LocationPasserbyPool] = {}

    async def get_or_spawn_passerby(
        self,
        world_id: str,
        map_id: str,
        sub_location_id: Optional[str] = None,
        spawn_hint: Optional[str] = None,
    ) -> PasserbyInstance:
        """获取或生成路人"""
        pool = await self._get_pool(world_id, map_id)

        # 检查是否有可复用的实例
        location_key = sub_location_id or map_id
        for inst in pool.active_instances.values():
            if (inst.sub_location_id or inst.map_id) == location_key:
                return inst

        # 检查是否达到上限
        if len(pool.active_instances) >= pool.config.max_concurrent:
            # 淘汰最旧的
            oldest = min(pool.active_instances.values(), key=lambda x: x.spawn_time)
            await self.despawn_passerby(world_id, map_id, oldest.instance_id)

        # 生成新路人
        return await self._spawn_passerby(world_id, map_id, sub_location_id, pool)

    async def despawn_passerby(
        self,
        world_id: str,
        map_id: str,
        instance_id: str,
        persist_memory: bool = True,
    ):
        """移除路人，可选合并记忆"""
        pool = await self._get_pool(world_id, map_id)
        instance = pool.active_instances.pop(instance_id, None)

        if instance and persist_memory and instance.interaction_count > 0:
            # 将交互贡献到共享记忆
            await self._contribute_to_shared_memory(
                world_id, map_id,
                f"{instance.name}与冒险者有过{instance.interaction_count}次对话"
            )

        # 持久化池状态
        await self._save_pool(world_id, map_id, pool)

    async def handle_passerby_dialogue(
        self,
        world_id: str,
        map_id: str,
        instance_id: str,
        player_message: str,
    ) -> Dict:
        """处理路人对话（强制使用FAST层）"""
        pool = await self._get_pool(world_id, map_id)
        instance = pool.active_instances.get(instance_id)

        if not instance:
            return {"error": "路人不存在"}

        # 获取共享记忆作为上下文
        shared_memory = await self._get_shared_memory(world_id, map_id)

        # 使用FAST层响应
        response = await self._tiered_ai.respond(
            world_id=world_id,
            npc_id=instance_id,
            npc_tier=NPCTier.PASSERBY,
            query=player_message,
            location_id=map_id,
            npc_profile={
                "name": instance.name,
                "personality": instance.personality_snippet,
                "appearance": instance.appearance,
                "shared_context": shared_memory,
            },
            force_tier=AITier.FAST,
        )

        # 更新交互计数
        instance.interaction_count += 1
        await self._save_pool(world_id, map_id, pool)

        return {
            "response": response.content,
            "speaker": instance.name,
            "tier_used": response.tier_used,
            "latency_ms": response.latency_ms,
        }

    async def _get_pool(self, world_id: str, map_id: str) -> LocationPasserbyPool:
        """获取或创建地点池"""
        key = f"{world_id}:{map_id}"
        if key not in self._pools:
            # 从Firestore加载或创建
            self._pools[key] = await self._load_pool(world_id, map_id)
        return self._pools[key]

    async def _spawn_passerby(
        self,
        world_id: str,
        map_id: str,
        sub_location_id: Optional[str],
        pool: LocationPasserbyPool,
    ) -> PasserbyInstance:
        """生成新路人"""
        # 从模板随机选择
        template_id = random.choice(pool.config.templates) if pool.config.templates else "generic"

        instance = PasserbyInstance(
            instance_id=str(uuid.uuid4()),
            template_id=template_id,
            map_id=map_id,
            sub_location_id=sub_location_id,
            name=self._generate_name(template_id),
            appearance=self._generate_appearance(template_id),
            personality_snippet=self._generate_personality(template_id),
            spawn_time=datetime.now(),
        )

        pool.active_instances[instance.instance_id] = instance
        await self._save_pool(world_id, map_id, pool)

        return instance

    async def _contribute_to_shared_memory(
        self,
        world_id: str,
        map_id: str,
        content: str,
    ):
        """贡献到共享记忆图谱"""
        from app.models.graph import MemoryNode  # 导入正确类型

        # 创建 MemoryNode 对象（不是 dict）
        node = MemoryNode(
            id=f"shared_{datetime.now().timestamp()}",
            type="location_memory",
            name=content[:50],  # 截取摘要作为名称
            properties={
                "content": content,
                "timestamp": datetime.now().isoformat(),
            },
        )
        # 使用新增的地点图谱方法
        await self._graph_store.upsert_location_node(
            world_id=world_id,
            map_id=map_id,
            node=node,
        )

    async def _get_shared_memory(self, world_id: str, map_id: str) -> str:
        """获取共享记忆摘要"""
        # 使用新增的地点图谱加载方法
        graph = await self._graph_store.load_location_graph(
            world_id=world_id,
            map_id=map_id,
        )

        if not graph or not graph.nodes:
            return ""

        # 提取最近的记忆节点（MemoryNode 对象）
        location_memories = [
            n for n in graph.nodes
            if n.type == "location_memory"
        ]
        recent_memories = sorted(
            location_memories,
            key=lambda x: x.properties.get("timestamp", "") if x.properties else "",
            reverse=True
        )[:5]

        return "\n".join([
            m.properties.get("content", "") if m.properties else ""
            for m in recent_memories
        ])

    # ========== 持久化方法（必须实现） ==========

    async def _load_pool(self, world_id: str, map_id: str) -> LocationPasserbyPool:
        """从Firestore加载路人池"""
        from google.cloud import firestore
        db = firestore.AsyncClient()

        doc_ref = db.collection("worlds").document(world_id)\
            .collection("maps").document(map_id)\
            .collection("passerby_pool").document("config")

        doc = await doc_ref.get()
        if doc.exists:
            data = doc.to_dict()
            return LocationPasserbyPool(
                map_id=map_id,
                config=PasserbySpawnConfig(**data.get("config", {})),
                active_instances={
                    k: PasserbyInstance(**v)
                    for k, v in data.get("active_instances", {}).items()
                },
                sentiment=data.get("sentiment", 0.0),
            )

        # 默认池
        return LocationPasserbyPool(
            map_id=map_id,
            config=PasserbySpawnConfig(),
        )

    async def _save_pool(self, world_id: str, map_id: str, pool: LocationPasserbyPool):
        """保存路人池到Firestore"""
        from google.cloud import firestore
        db = firestore.AsyncClient()

        doc_ref = db.collection("worlds").document(world_id)\
            .collection("maps").document(map_id)\
            .collection("passerby_pool").document("config")

        await doc_ref.set({
            "config": pool.config.dict(),
            "active_instances": {
                k: v.dict() for k, v in pool.active_instances.items()
            },
            "sentiment": pool.sentiment,
            "updated_at": datetime.now(),
        }, merge=True)

    async def _save_passerby_config(
        self,
        world_id: str,
        map_id: str,
        config: PasserbySpawnConfig
    ):
        """保存路人池配置"""
        from google.cloud import firestore
        db = firestore.AsyncClient()

        doc_ref = db.collection("worlds").document(world_id)\
            .collection("maps").document(map_id)\
            .collection("passerby_pool").document("config")

        await doc_ref.set({
            "config": config.dict(),
            "created_at": datetime.now(),
        }, merge=True)

    # ========== 辅助方法 ==========

    def _generate_name(self, template_id: str) -> str:
        names = ["旅人", "商人", "农夫", "流浪者", "朝圣者"]
        return random.choice(names)

    def _generate_appearance(self, template_id: str) -> str:
        return "普通的外貌"

    def _generate_personality(self, template_id: str) -> str:
        return "友好但有些拘谨"
```

### 4.5 集成修改

**文件: `app/services/game_master_service.py`**

```python
class GameMasterService:
    def __init__(self, ...):
        # ... 现有 ...
        self.passerby_service = PasserbyService(
            self.graph_store,
            self._tiered_ai,
        )

    async def _handle_interact(self, context, target_name):
        """修改：支持路人交互"""
        # 检查是否为路人
        if self._is_passerby_request(target_name, context):
            passerby = await self.passerby_service.get_or_spawn_passerby(
                world_id=context.world_id,
                map_id=context.current_location,
                sub_location_id=context.current_sub_location,
            )
            return {
                "type": "passerby_spawned",
                "passerby": passerby.dict(),
            }

        # ... 正常NPC交互逻辑 ...

    async def _handle_dialogue(self, context, npc_id, player_message):
        """修改：路人对话走单独路径"""
        if self._is_passerby_id(npc_id):
            return await self.passerby_service.handle_passerby_dialogue(
                world_id=context.world_id,
                map_id=context.current_location,
                instance_id=npc_id,
                player_message=player_message,
            )

        # ... 正常NPC对话逻辑（使用TieredAI）...
```

**文件: `app/tools/world_initializer/character_loader.py`**

```python
class CharacterLoader:
    async def load_characters(self, world_id, characters_data):
        passerby_templates = []

        for char in characters_data.characters:
            if char.tier == NPCTier.PASSERBY:
                # 不再跳过，收集为模板
                passerby_templates.append(char)
                continue

            # ... 正常角色加载 ...

        # 初始化路人池
        await self._init_passerby_pools(world_id, passerby_templates)

    async def _init_passerby_pools(self, world_id, templates):
        """初始化各地点的路人池"""
        # 按地点分组模板
        location_templates = {}
        for t in templates:
            loc = t.default_map or "default"
            if loc not in location_templates:
                location_templates[loc] = []
            location_templates[loc].append(t.id)

        # 为每个地点创建池配置
        for map_id, template_ids in location_templates.items():
            config = PasserbySpawnConfig(templates=template_ids)
            # 存储到 Firestore
            await self._save_passerby_config(world_id, map_id, config)
```

### 4.6 GraphStore扩展

> **关键修正**：
> 1. 保留原签名，新增方法支持location类型
> 2. `upsert_node` 需要 `MemoryNode` 对象，不是 dict

**文件: `app/services/graph_store.py`**

```python
class GraphStore:
    # 保留原有签名
    async def load_graph(
        self,
        world_id: str,
        graph_type: str,  # 现有参数
        character_id: Optional[str] = None,  # 现有参数
    ) -> GraphData:
        """保持不变"""
        # ... 现有实现 ...

    # 新增方法：加载地点图谱
    async def load_location_graph(
        self,
        world_id: str,
        map_id: str,
        sub_location_id: Optional[str] = None,
    ) -> GraphData:
        """新增：加载地点级图谱"""
        if sub_location_id:
            path = f"worlds/{world_id}/maps/{map_id}/sub_locations/{sub_location_id}/graphs/shared_memory"
        else:
            path = f"worlds/{world_id}/maps/{map_id}/graphs/shared_memory"

        # 复用现有加载逻辑
        return await self._load_graph_from_path(path)

    # 新增方法：保存到地点图谱
    async def upsert_location_node(
        self,
        world_id: str,
        map_id: str,
        node: MemoryNode,  # 必须是 MemoryNode 对象
        sub_location_id: Optional[str] = None,
    ) -> None:
        """新增：向地点图谱添加节点"""
        if sub_location_id:
            path = f"worlds/{world_id}/maps/{map_id}/sub_locations/{sub_location_id}/graphs/shared_memory"
        else:
            path = f"worlds/{world_id}/maps/{map_id}/graphs/shared_memory"

        await self._upsert_node_to_path(path, node)
```

### 4.7 修改文件清单

| 文件 | 修改类型 | 内容 |
|------|----------|------|
| `app/models/passerby.py` | **新建** | PasserbyInstance, LocationPasserbyPool |
| `app/services/passerby_service.py` | **新建** | PasserbyService |
| `app/services/graph_store.py` | 修改 | 支持location/sub_location图谱类型 |
| `app/services/game_master_service.py` | 修改 | 集成PasserbyService |
| `app/tools/world_initializer/character_loader.py` | 修改 | 初始化路人池 |

---

## 测试验证方案

### API端点测试

```bash
# 正确的API路径
BASE_URL="http://localhost:8000/api/gm"

# 1. 测试子地点导航
curl -X POST "$BASE_URL/{world_id}/sessions/{session_id}/input" \
  -H "Content-Type: application/json" \
  -d '{"input": "我想去酒馆"}'

# 2. 测试三层AI（观察tier_used和latency_ms）
# 与MAIN角色对话
curl -X POST "$BASE_URL/{world_id}/sessions/{session_id}/input" \
  -d '{"input": "和女神官聊聊最近的事"}'

# 与路人对话
curl -X POST "$BASE_URL/{world_id}/sessions/{session_id}/input" \
  -d '{"input": "和那边的旅人打个招呼"}'

# 3. 测试章节解锁
# 尝试进入未解锁地图
curl -X POST "$BASE_URL/{world_id}/sessions/{session_id}/input" \
  -d '{"input": "去哥布林洞穴"}'
# 预期返回: {"error": "该地区尚未解锁"}
```

### 单元测试

```bash
# 运行所有新模块测试
pytest tests/test_sub_locations.py -v
pytest tests/test_tiered_ai.py -v
pytest tests/test_narrative_service.py -v
pytest tests/test_passerby_service.py -v

# 集成测试
PYTHONPATH=. pytest tests/test_integration.py -v -s
```

### 性能验证

```python
# 测试Fast层延迟目标
async def test_fast_tier_latency():
    response = await tiered_ai.respond(
        ...,
        force_tier=AITier.FAST
    )
    assert response.latency_ms < 100  # 目标<100ms
```

---

## 文件清单汇总

### 新建文件 (10个)

| 文件 | 模块 |
|------|------|
| `app/services/context_cache.py` | 3 |
| `app/services/subconscious_prewarmer.py` | 3 |
| `app/services/tiered_ai_service.py` | 3 |
| `app/models/narrative.py` | 1 |
| `app/services/narrative_service.py` | 1 |
| `app/models/passerby.py` | 4 |
| `app/services/passerby_service.py` | 4 |
| `data/goblin_slayer/structured/mainlines.json` | 1 |
| `tests/test_tiered_ai.py` | 3 |
| `tests/test_narrative_service.py` | 1 |

### 修改文件 (8个)

| 文件 | 模块 | 修改内容 |
|------|------|----------|
| `app/services/area_navigator.py` | 2 | SubLocation定义，resolve_location() |
| `app/services/game_master_service.py` | 全部 | 核心集成点 |
| `app/config.py` | 3 | 三层模型配置 |
| `app/services/pro_llm_service.py` | 3 | model_override, enable_tools |
| `app/services/graph_store.py` | 4 | 支持location图谱类型 |
| `app/tools/world_initializer/character_loader.py` | 4 | 路人池初始化 |
| `app/routers/game_master.py` | 2 | 子地点API |
| `data/goblin_slayer/structured/maps.json` | 2 | sub_locations数据 |

---

## 向后兼容保证

1. **resolve_location_name()** 签名不变，新增 resolve_location()
2. **key_features** 保留，自动转换为默认子地点
3. **现有NPC对话流程** 不变，分层路由透明集成
4. **Firestore路径** 与现有 maps/{map_id} 一致
5. **session.metadata** 扩展而非替换
# 注意：本文档基于旧架构（GameMasterService / gm_flash_service），当前已迁移至 Admin Layer（admin_coordinator / admin/event_service）。仅供历史参考。
