# V3 管线全流程详解

整个 `process_player_input_v3()` 方法位于 `admin_coordinator.py:428-1101`，共约 670 行。我按实际执行顺序，把它分成 A/B/C 三大阶段来讲：

---

## A 阶段：预处理（准备一切上下文）

**做的事**：在 LLM 开口之前，把它需要知道的所有信息都准备好。

### A1. 基础数据加载（行 452-478）

**参与文件**：
- `admin_coordinator.py` — 发起调度
- `character_store` — 取出玩家角色数据（种族、职业、属性等）
- `world_runtime.py` — 获取当前地点快照（名称、描述、NPC、可前往的目的地）
- `party_service.py` — 获取队伍信息（队友是谁、什么角色、什么性格）
- `session_history_manager` — 拿到对话历史（最近的聊天记录，用于 LLM 理解上下文）
- `narrative_service` — 加载叙事数据（当前章节、主线、事件定义等）

**简单说**：这一步是「收集情报」，把角色、地点、队伍、历史、章节信息全部拿到手，装进一个叫 `base_context` 的大字典里。

### A2. 故事导演预评估（行 479-503）

**参与文件**：
- `story_director.py` — 两阶段评估的「第一阶段」
- `condition_engine.py` — 被 StoryDirector 调用，做纯机械条件检查

**做的事**：扫描当前章节的所有事件，看哪些事件的触发条件已经满足了。

比如事件「黑暗精灵袭击」的触发条件是 `LOCATION=暗巷 AND TIME_PASSED>=day3`。ConditionEngine 会逐个检查——地点对了吗？时间到了吗？

**结果分两类**：
- `auto_fired_events`：纯机械条件全部满足的事件 → 立即触发
- `pending_flash_conditions`：含有 `FLASH_EVALUATE` 类型（需要 LLM 语义判断的，比如「玩家是否表现出恐惧」）→ 打包留给下一步让 LLM 评估

### A3. 记忆预填充（行 505-555）

**参与文件**：
- `recall_orchestrator.py` — 编排多作用域的记忆召回
- `spreading_activation.py` — 扩散激活算法，在知识图谱上找相关节点
- `memory_graph.py` — 承载知识图谱数据的 NetworkX 图结构
- `graph_store.py` — 从 Firestore 加载图谱数据

**做的事**：并行启动记忆召回任务——给玩家和每个队友各开一个异步任务。

**原理**：以当前场景的关键词（地点名、NPC 名等）作为「种子」，在知识图谱上做扩散激活。就像你在脑中想到「酒馆」会自然联想到「酒保」→「任务委托」→「悬赏公告」。算法就是模拟这个过程，找出最相关的记忆节点。

**注意**：玩家的记忆任务是 `await` 阻塞等待的（后续步骤需要它的结果），而队友的记忆任务在后台并行跑。

---

## B 阶段：Agentic 核心会话（LLM 自主行动）

**做的事**：把所有信息交给 LLM，让它自己决定该做什么、调什么工具、说什么话。

### B1. Agentic 会话（行 557-578）

**参与文件**：
- `flash_cpu_service.py` 的 `agentic_process()` — 构造系统提示 + 调用 LLM
- `agentic_tools.py` (`AgenticToolRegistry`) — 把游戏操作包装成 LLM 可调用的函数
- `app/prompts/flash_agentic_system.md` — 系统提示词，告诉 LLM 它是谁、能用什么工具
- LLM 服务 (`llm_service`) — 实际和 Gemini API 通信

**做的事**：这是整个 V3 管线最核心的一步。

FlashCPU 把所有上下文（世界状态、角色信息、对话历史、记忆召回结果、待评估的故事条件）打包成一个超长 prompt，发给 Gemini。

**Gemini 会自主决定要做什么**：
- 玩家说「去酒馆」→ LLM 调用 `navigate` 工具
- 玩家说「和老板聊聊」→ LLM 调用 `npc_dialogue` 工具
- 玩家说「我环顾四周」→ LLM 不调工具，直接生成描述

`AgenticToolRegistry` 提供了约 15-20 个工具（导航、NPC 对话、战斗、添加物品、时间推进等）。LLM 可以在最多 24 轮内连续调用多个工具。

**最终返回 `AgenticResult`**：
- `narration`：LLM 生成的 GM 叙述
- `tool_calls`：调用了哪些工具（名称、参数、是否成功）
- `flash_results`：每个工具的执行结果（状态变更等）
- `story_condition_results`：LLM 对语义条件的评估结果

### B2. 工具执行校验（行 580-679）

**参与文件**：
- `agentic_enforcement.py` 的 `evaluate_agentic_tool_usage()` — 校验 LLM 是否做了该做的事
- `flash_cpu_service.py` 的 `run_required_tool_repair()` — 修复循环

**做的事**：检查 LLM 的行为是否合理。

比如玩家说了「去酒馆」，但 LLM 只生成了一段描述文字却没有调用 `navigate` 工具——这就是「漏操作」。

**校验逻辑**：会根据推断出的意图类型，检查必需的工具是否被调用了。如果开启了 `strict` 模式且校验失败：
1. 先尝试修复：重新构造一个只暴露缺失工具的约束环境，让 LLM 再跑一次
2. 修复后再次校验
3. 如果还是失败 → 抛出 `AgenticToolExecutionRequiredError` 异常

---

## C 阶段：后处理（善后工作）

**做的事**：Agentic 会话结束后，做故事推进、队友响应、记录历史等收尾工作。

### C1. 上下文编排与记忆注入（行 686-764）

**参与文件**：
- `admin_coordinator.py` 的 `_run_curation_pipeline()` 和 `_assemble_context()` — 合并上下文
- `recall_orchestrator.py` — 收割队友记忆预填充结果

**做的事**：把玩家记忆召回结果、Agentic 会话中 LLM 主动调用 `recall_memory` 的种子、工具执行结果，全部合并成完整的上下文包。同时收割之前并行启动的队友记忆任务的结果。

这一步确保后续队友响应环节能拿到充分的记忆信息。

### C2. 故事导演后评估（行 766-801）

**参与文件**：
- `story_director.py` — 两阶段评估的「第二阶段」
- `condition_engine.py` — 再次参与条件检查
- `narrative_service` — 处理进度刷新

**做的事**：拿到 LLM 的语义条件评估结果后，再跑一遍事件检查。

A2 阶段留下的 `pending_flash_conditions`，现在有了 LLM 的回答（「是的，玩家表现出了恐惧」），StoryDirector 把这些结果合并进来，判断哪些新事件可以触发了。

同时评估章节转换条件——是否该推进到下一章。

### C3. 事件计数与节奏控制（行 830-906）

**参与文件**：
- `admin_coordinator.py` — 事件去重、NPC 交互计数、冷却更新
- `narrative_service` — 保存叙事进度

**做的事**：
- 合并 pre-fired + post-fired + agentic 触发的事件，去重
- 统计 NPC 交互次数（条件引擎 `NPC_INTERACTED` 会用到）
- 更新事件冷却计时器
- 推进章节内回合数、停滞检测
- 保存进度到 Firestore

### C4. 章节转换（行 908-958）

**参与文件**：
- `narrative_service` — 执行章节切换（解锁新地图、更新进度）
- `state_manager.py` — 更新会话状态中的 `chapter_id` / `area_id`
- `admin_coordinator.py` 的 `_generate_chapter_transition()` — 生成转换叙述

**做的事**：如果 StoryDirector 判定需要转章，在这里实际执行——切换到新章节、解锁新地图、生成「第二章：暗影来袭」这样的过渡叙述，拼接到 GM 回复的末尾。

### C5. 队友响应（行 960-1008）

**参与文件**：
- `teammate_response_service.py` — 队友 AI 决策 + 生成响应
- `party_service.py` — 导航后同步队友位置
- `instance_manager.py` — NPC 实例池（管理队友的上下文窗口）
- `context_window.py` — 200K token 上下文窗口管理
- `app/prompts/teammate_decision.md` — 队友决策提示词
- `app/prompts/teammate_response.md` — 队友响应提示词

**做的事**：每个队友先做「决策」——这一轮我要不要说话？（依据性格、相关度、场景等判断）。决定要说话的队友再生成实际响应。

同时，如果这一轮玩家做了导航操作，队友位置会自动同步。

### C6. 事件分发到队友图谱（行 1001-1008）

**参与文件**：
- `event_service.py` — 事件入图
- `event_llm_service.py` — 视角转换（可选）
- `graph_store.py` — 写入各角色的知识图谱

**做的事**：把这一轮发生的事情写入每个队友的个人记忆图谱。这样下次召回记忆时，他们能「记住」之前发生过什么。

### C7. 历史记录与图谱化（行 1010-1040）

**参与文件**：
- `session_history_manager` — 记录本轮对话（玩家输入 + GM 回复 + 队友回复）
- `memory_graphizer.py` — 当历史过长时，把旧对话转化为知识图谱节点

**做的事**：
- 记录本轮交互到会话历史
- 检测输出异常（比如 LLM 跑出角色、token 溢出）
- 如果历史积累到一定量（80%+ 阈值），异步触发图谱化——把老对话从「短期记忆」搬到「长期知识图谱」

### C8. 组装最终响应（行 1042-1101）

**参与文件**：
- `admin_coordinator.py` — 构造 `CoordinatorResponse`

**做的事**：把所有结果打包成最终响应返回给前端：
- `narration`：GM 叙述
- `teammate_responses`：队友的回复
- `available_actions`：玩家可执行的操作
- `state_delta`：状态变更
- `story_events`：触发的故事事件
- `chapter_info`：章节信息
- `image_data`：场景图片（如果生成了）
- `metadata`：大量调试/追踪信息

---

## 文件职责速查表

| 文件 | 一句话职责 | 参与阶段 |
|------|-----------|---------|
| `admin_coordinator.py` | 总指挥，串联所有步骤 | 全程 |
| `flash_cpu_service.py` | 构造 prompt 并调用 LLM 执行 agentic 会话 | B1, B2 |
| `agentic_tools.py` | 把游戏操作包装成 LLM 可调用的工具 | B1 |
| `agentic_enforcement.py` | 校验 LLM 是否做了该做的操作 | B2 |
| `story_director.py` | 两阶段故事事件评估（pre + post） | A2, C2 |
| `condition_engine.py` | 纯机械条件检查（地点、时间、NPC 交互等） | A2, C2 |
| `recall_orchestrator.py` | 编排多作用域的记忆召回 | A3, C1 |
| `spreading_activation.py` | 在图谱上做扩散激活找相关记忆 | A3 |
| `memory_graph.py` | 内存中的 NetworkX 知识图谱 | A3 |
| `graph_store.py` | Firestore 图谱持久化 | A3, C6 |
| `world_runtime.py` | 导航/时间/地点操作的执行层 | A1（取地点）, B1（工具内部调用） |
| `state_manager.py` | 内存中的会话状态 + 增量追踪 | C4 |
| `party_service.py` | 队伍管理（增删成员、位置同步） | A1, C5 |
| `teammate_response_service.py` | 队友每轮的决策和响应生成 | C5 |
| `event_service.py` | 事件入图 + 分发给角色 | C6 |
| `event_llm_service.py` | LLM 解析事件 + 视角转换 | C6 |
| `memory_graphizer.py` | 对话历史 → 知识图谱节点 | C7 |
| `narrative_service` | 叙事数据（章节/事件/进度/转换） | A1, A2, C2, C3, C4 |

---

## 下一步

你想从哪个阶段或哪个文件开始优化？